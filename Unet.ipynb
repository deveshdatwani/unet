{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deveshdatwani/unet/blob/main/Unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KBspqFjdMHtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c784a42-cee7-4b5c-cf37-73487a557211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE IS cuda:0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'DEVICE IS {DEVICE}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I92i0o2q-Np3"
      },
      "source": [
        "# Lib Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d00yrmWdor9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e58cc0-b7f4-4536-9dc9-09a19c931ee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "drive.mount('/content/drive')\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Resize, RandomRotation\n",
        "import torchvision.transforms.functional as TF\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "from torchvision.io import read_image, ImageReadMode as iomode\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torch.optim import SGD, Adam, RMSprop\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import MSELoss\n",
        "import numpy as np\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjoCZkz89w_S"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qcdIgbgSo3BU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchvision.transforms import ToTensor, Resize, InterpolationMode, Normalize\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(\n",
        "            self, in_channels=3, out_channels=1, features=[64, 128, 256, 512],\n",
        "    ):\n",
        "        super(UNet, self).__init__()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Down part of UNET\n",
        "        for feature in features:\n",
        "            self.downs.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # Up part of UNET\n",
        "        for feature in reversed(features):\n",
        "            self.ups.append(\n",
        "                nn.ConvTranspose2d(\n",
        "                    feature*2, feature, kernel_size=2, stride=2,\n",
        "                )\n",
        "            )\n",
        "            self.ups.append(DoubleConv(feature*2, feature))\n",
        "\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "        self.final_conv = (nn.Conv2d(features[0], out_channels, kernel_size=1))\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        for idx in range(0, len(self.ups), 2):\n",
        "            x = self.ups[idx](x)\n",
        "            skip_connection = skip_connections[idx//2]\n",
        "\n",
        "            if x.shape != skip_connection.shape:\n",
        "                x = TF.resize(x, size=skip_connection.shape[2:], interpolation=InterpolationMode.BILINEAR, antialias=True)\n",
        "\n",
        "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "            x = self.ups[idx+1](concat_skip)\n",
        "\n",
        "        return self.sigmoid(self.final_conv(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q79QJleh93AP"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GHMDBtwisHiu"
      },
      "outputs": [],
      "source": [
        "class ResizeSample(object):\n",
        "    def __init__(self):\n",
        "        self.image_size = [572, 572]\n",
        "        self.mask_size = [572, 572]\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image = sample['image']\n",
        "        mask = sample['mask']\n",
        "        image = Resize(self.image_size, interpolation=InterpolationMode.BILINEAR, antialias=True )(image)\n",
        "        mask = Resize(self.mask_size, interpolation=InterpolationMode.BILINEAR, antialias=True )(mask) \n",
        "        sample = {'image': image, 'mask': mask}\n",
        "        \n",
        "        return sample \n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, mask = sample['image'], sample['mask']\n",
        "        image = image.transpose((2,0,1))    \n",
        "\n",
        "        return {'image': torch.from_numpy(image), 'mask':torch.from_numpy(mask).unsqueeze(0)}\n",
        "\n",
        "\n",
        "class NormalizeImage():\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "    \n",
        "    def __call__(self, sample):\n",
        "        image = sample['image'] \n",
        "        mask = sample['mask']\n",
        "        image_normalized = Normalize(self.mean, self.std)(image)\n",
        "        mask_normalized = mask \n",
        "        # Normalize(self.mean, self.std)(mask)\n",
        "        sample = {'image': image_normalized, 'mask': mask_normalized}\n",
        "\n",
        "        return sample\n",
        "\n",
        "class Rotate(object):\n",
        "    def __init__(self, degrees=(0,180)):\n",
        "        self.degrees = degrees\n",
        "        self.rotator = RandomRotation(degrees)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        instance = sample['image']\n",
        "        target = sample['mask']\n",
        "        \n",
        "        angle = np.random.choice([-30.0, -15.0, 0.0, 15.0, 30.0])\n",
        "        \n",
        "        instance = TF.rotate(instance, angle)\n",
        "        target = TF.rotate(target, angle)\n",
        "        sample = {'image':instance, 'mask':target}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "\n",
        "class Caravan(Dataset):\n",
        "    def __init__(self, root_dir, json=None):\n",
        "       self.root_dir = root_dir\n",
        "       self.train_images_dir = os.path.join(root_dir, \"train\")\n",
        "       self.train_images = os.listdir(self.train_images_dir)\n",
        "       self.sample_transform = transforms.Compose([ToTensor(), ResizeSample()])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(os.listdir(self.train_images_dir))\n",
        "\n",
        "\n",
        "    def transform(self, sample):\n",
        "        sample = self.sample_transform(sample)\n",
        "\n",
        "        return sample \n",
        "    \n",
        "\n",
        "    def get_mask_address(self, image_address):\n",
        "        image_name = image_address.split('/')[-1]\n",
        "        mask_address = self.root_dir + '/train_masks/' + image_name[:-4] + '_mask.gif'\n",
        "\n",
        "        return mask_address\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_address = os.path.join(self.train_images_dir, self.train_images[idx])\n",
        "        mask_address = self.get_mask_address(image_address)   \n",
        "        image = np.array(Image.open(image_address), dtype=np.float32) / 255.0\n",
        "        mask = np.array(Image.open(mask_address), dtype=np.float32)\n",
        "        \n",
        "        sample = {'image': image, 'mask': mask}\n",
        "        sample = self.sample_transform(sample)\n",
        "        \n",
        "        return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLz4KkYI-4CD"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c2JjnhVl-7N6"
      },
      "outputs": [],
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=0.01):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    \n",
        "    def forward(self, pred, target, epsilon=1e-8):\n",
        "        numerator = 2 * torch.sum(pred * target)\n",
        "        denominator = torch.sum(pred + target) + epsilon\n",
        "        dice_coeff = numerator / denominator\n",
        "        loss = 1 - dice_coeff\n",
        "    \n",
        "        return loss\n",
        "\n",
        "\n",
        "    # def forward(self, prediction, target):\n",
        "    #     # prediction[prediction > 0.5] = 1\n",
        "    #     # target[target > 0.5] = 1\n",
        "    #     e = 1e-4\n",
        "\n",
        "    #     prediction_flat = prediction.view(-1)\n",
        "    #     target_flat = target.view(-1)\n",
        "\n",
        "    #     intersection = (prediction_flat).sum()\n",
        "    #     prediction_sum  = (prediction_flat).sum()\n",
        "    #     target_sum = (target_flat).sum()\n",
        "    #     loss = 1 - (((2 * intersection) + e) / ((prediction_sum + target_sum)) + e) \n",
        "\n",
        "    #     return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xh32_9J97be"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nPclQwoz84ek"
      },
      "outputs": [],
      "source": [
        "class Loader(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, dataset, batch_size):\n",
        "        return DataLoader(dataset, batch_size, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hGonBgS9_CU"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9U0WBP3qUpQ",
        "outputId": "700a8561-4e33-41c3-cae3-a89108e3203b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE IS cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "# TRAINING LOOP\n",
        "class Trainer(object):\n",
        "    def __init__(self, model=None, epochs=16, batch_size=2, path=None):\n",
        "      \n",
        "        self.model = model\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.dataset = Caravan(PATH)\n",
        "        self.dataloader = Loader()\n",
        "        self.data_loader = self.dataloader(dataset=self.dataset, batch_size=self.batch_size)\n",
        "        self.optim = SGD(params=model.parameters(), lr=0.001, momentum=0.99)\n",
        "        self.criterian = DiceLoss()\n",
        "        self.checkpoint_loss = float('inf')\n",
        "        # self.criterian = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    def __call__(self):\n",
        "        DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f'DEVICE IS {DEVICE}')\n",
        "        \n",
        "        for epoch_number in tqdm(range(self.epochs)):\n",
        "            running_loss = 0\n",
        "            \n",
        "            for i, data in enumerate(self.data_loader):\n",
        "                instance, mask = data['image'], data['mask']\n",
        "                instance = torch.nn.functional.normalize(instance)\n",
        "                instance = instance.to(device=DEVICE)\n",
        "                mask = mask.to(device=DEVICE)\n",
        "                self.optim.zero_grad()\n",
        "                prediction = model(instance)\n",
        "                loss = self.criterian(prediction, mask)               \n",
        "                loss.backward()\n",
        "                self.optim.step()\n",
        "                running_loss += loss.item()\n",
        "        \n",
        "                \n",
        "                if i % 5 == 0:\n",
        "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                         epoch_number, i * len(data), len(self.dataset),\n",
        "                         100. * i / len(self.data_loader), running_loss / 5))\n",
        "                    running_loss = 0\n",
        "\n",
        "\n",
        "                if running_loss < self.checkpoint_loss:\n",
        "                    torch.save({\n",
        "                                'epoch': epoch_number,\n",
        "                                'model_state_dict': model.state_dict(),\n",
        "                                'optimizer_state_dict': self.optim.state_dict(),\n",
        "                                'loss': running_loss,\n",
        "                                }, CHECKPOINT_PATH)\n",
        "                    self.checkpoint_loss = running_loss\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    EPOCHS = 10\n",
        "    BATCH_SIZE = 2\n",
        "    PATH = '/content/drive/MyDrive/Caravan'\n",
        "    CHECKPOINT_PATH = 'model.pt'\n",
        "\n",
        "    model = UNet()\n",
        "    model.to(device=DEVICE)\n",
        "    trainer = Trainer(model=model, batch_size=BATCH_SIZE, epochs=EPOCHS, path=PATH)\n",
        "    trainer()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "5AiztYocDjQi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nk-d_PjFqguz"
      },
      "outputs": [],
      "source": [
        "CHECKPOIN_PATH = 'model.pt'\n",
        "dataset = Caravan(PATH)\n",
        "dataloader = Loader()\n",
        "data_loader = dataloader(dataset=dataset, batch_size=1)\n",
        "sample = next(iter(data_loader)) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet()\n",
        "checkpoint = torch.load(CHECKPOIN_PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "metadata": {
        "id": "RUMuH4WDDxf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtxqUyuqqwVq"
      },
      "outputs": [],
      "source": [
        "instance = sample['image']\n",
        "mask = sample['mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HU8coFKPq2GL"
      },
      "outputs": [],
      "source": [
        "pred = model(instance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g80ve-XVq513"
      },
      "outputs": [],
      "source": [
        "plt.imshow(pred[0].detach().cpu().numpy().transpose(1,2,0), cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgBD5Bmkresm"
      },
      "outputs": [],
      "source": [
        "plt.imshow(mask[0].detach().cpu().numpy().transpose(1,2,0), cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred.shape"
      ],
      "metadata": {
        "id": "Mfs7n4OSEReo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "I92i0o2q-Np3",
        "NjoCZkz89w_S",
        "Q79QJleh93AP",
        "9xh32_9J97be",
        "0hGonBgS9_CU",
        "5AiztYocDjQi"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMoImDyeTI2sxglcvaxX7Fw",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}